<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>ch2</title>
  <style>
    html {
      line-height: 1.5;
      font-family: Georgia, serif;
      font-size: 20px;
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 1em;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, 'Lucida Console', Consolas, monospace;
      font-size: 85%;
      margin: 0;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      background-color: #1a1a1a;
      border: none;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    span.underline{text-decoration: underline;}
    div.column{display: inline-block; vertical-align: top; width: 50%;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
  </style>
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
</head>
<body>
<h1 id="chapter-2---application-layer">CHAPTER 2 - APPLICATION
LAYER</h1>
<h2 id="principles-of-network-applications">2.1 Principles of Network
Applications</h2>
<h3 id="network-application-architectures">2.1.1 Network Application
Architectures</h3>
<ul>
<li><p>From the application developer’s perspective, the network
architecture is fixed and provides a specific set of services to
applications. The application architecture, on the other hand, is
designed by the application developer and dictates how the application
is structured over the various end systems.</p></li>
<li><p>In a <strong>client-server architecture</strong>, there is an
always-on host, called the server, which services requests from many
other hosts, called clients.</p></li>
<li><p>Another characteristic of the client-server architecture is that
the server has a fixed, well-known address, called an <strong>IP
address</strong></p></li>
<li><p>Some of the better-known applications with a client-server
architecture include the <strong>Web</strong>, <strong>FTP</strong>,
<strong>Telnet</strong>, and <strong>e-mail</strong></p></li>
<li><p>Often in a client-server application, a single-server host is
incapable of keeping up with all the requests from clients.</p></li>
<li><p>For this reason, a <strong>data center</strong>, housing a large
number of hosts, is often used to create a powerful virtual
server</p></li>
<li><p>Google has 19 data centers distributed around the world, which
collectively handle search, YouTube, Gmail, and other services.</p></li>
<li><p>A <strong>data center</strong> can have hundreds of thousands of
servers, which must be powered and maintained.</p></li>
<li><p>In a <strong>P2P architecture</strong>, there is minimal (or no)
reliance on dedicated servers in data centers.</p></li>
<li><p>Instead the application exploits direct communication between
pairs of intermittently connected hosts, called
<strong>peers</strong>.</p></li>
<li><p>P2P architectures are also cost effective, since they normally
don’t require significant server infrastructure and server bandwidth (in
contrast with clients-server designs with datacenters).</p></li>
</ul>
<h3 id="process-communicating">2.1.2 Process Communicating</h3>
<ul>
<li>Processes on two different end systems communicate with each other
by exchanging <strong>messages</strong> across the computer network</li>
<li>Processes communicating with each other reside in the application
layer of the five-layer protocol stack.</li>
</ul>
<h4 id="client-and-server-processes">Client and Server Processes</h4>
<ul>
<li>In a P2P file-sharing system, a file is transferred from a process
in one peer to a process in another peer</li>
<li>For each pair of communicating processes, we typically label one of
the two processes as the <strong>client</strong> and the other process
as the <strong>server</strong>.</li>
<li>With the Web, a browser is a client process and a Web server is a
server process</li>
<li>With P2P file sharing, the peer that is downloading the file is
labeled as the client, and the peer that is uploading the file is
labeled as the server</li>
<li>A process in a P2P file-sharing system can both upload and download
files</li>
<li>In P2P file sharing, when Peer A asks Peer B to send a specific
file, Peer A is the client and Peer B is the server in the context of
this specific communication session.</li>
</ul>
<h4 id="the-interface-between-the-process-and-the-computer-network">The
Interface Between the Process and the Computer Network</h4>
<ul>
<li>A process sends messages into, and receives messages from, the
network through a software interface called a
<strong>socket</strong>.</li>
<li>A <strong>socket</strong> is the interface between the application
layer and the transport layer within a host. It is also referred to as
the <strong>Application Programming Interface (API)</strong> between the
application and the network, since the socket is the programming
interface with which network applications are built</li>
<li>Once the application developer chooses a transport protocol
(TCP/UDP) (if a choice is available), the application is built using the
transport-layer services provided by that protocol.</li>
</ul>
<h4 id="addressing-processes">Addressing Processes</h4>
<ul>
<li>To identify the receiving process, two pieces of information need to
be specified: <strong>(1) the address of the host</strong> and
<strong>(2) an identifier that specifies the receiving process in the
destination host.</strong></li>
<li>In the Internet, the host is identified by its <strong>IP
address</strong></li>
<li>An IP address is a 32-bit value that uniquely identifies a host</li>
<li>In addition to knowing the address of the host to which a message is
destined, the sending process must also identify the receiving process
(more specifically, the receiving socket) running in the host. This is
known as the <strong>port number</strong></li>
<li>Popular applications have been assigned specific port numbers. For
example, a Web server is identified by port number 80.</li>
<li>A mail server process (using the SMTP protocol) is identified by
port number 25.</li>
</ul>
<h3 id="transport-services-available-to-applications">2.1.3 Transport
Services Available to Applications</h3>
<ul>
<li>The application at the sending side pushes messages through the
socket.</li>
<li>At the other side of the socket, the transport-layer protocol has
the responsibility of getting the messages to the socket of the
receiving process.</li>
<li>When you develop an application, you must choose one of the
available transport-layer protocols.</li>
<li>We can broadly classify the possible services along four dimensions:
<ul>
<li>reliable data transfer</li>
<li>throughput</li>
<li>timing</li>
<li>security</li>
</ul></li>
</ul>
<h4 id="reliable-data-transfer">Reliable Data Transfer</h4>
<ul>
<li>Web document transfers, and financial applications–data loss can
have devastating consequences</li>
<li>Thus, to support these applications, something has to be done to
guarantee that the data sent by one end of the application is delivered
correctly and completely to the other end of the application.</li>
<li>If a protocol provides such a guaranteed data delivery service, it
is said to provide <strong>reliable data transfer</strong>.</li>
<li>One important service that a transport-layer protocol can
potentially provide to an application is process-to-process reliable
data transfer</li>
<li>When a transport protocol (TCP/UDP) provides this service, the
sending process can just pass its data into the socket and know with
complete confidence that the data will arrive without errors at the
receiving process</li>
<li>When a transport-layer protocol doesn’t provide reliable data
transfer, some of the data sent by the sending process may never arrive
at the receiving process.</li>
<li>This may be acceptable for <strong>loss-tolerant
applications</strong>, most notably multimedia applications such as
conversational audio/video that can tolerate some amount of data loss.
(a.k.a lossy compression, get it right, book)</li>
</ul>
<h4 id="throughput">Throughput</h4>
<ul>
<li>Because other sessions will be sharing the bandwidth along the
network path, and because these other sessions will be coming and going,
the available <strong>throughput</strong> can fluctuate with time.</li>
<li>These observations lead to another natural service that a
transport-layer protocol could provide, namely, guaranteed available
throughput at some specified rate</li>
<li>With such a service, the application could request a guaranteed
throughput of <strong>r</strong> bits/sec, and the transport protocol
(TCP/UDP) would then ensure that the available throughput is always at
least <strong>r</strong> bits/sec</li>
<li>If the transport protocol (TCP/UDP) cannot provide this throughput,
the application would need to encode at a lower rate (and receive enough
throughput to sustain this lower coding rate) or may have to give up,
since receiving, say, half of the needed throughput is of little or no
use</li>
<li>Applications that have throughput requirements are said to be
<strong>bandwidth-sensitive applications</strong></li>
<li>While bandwidth-sensitive applications have specific throughput
requirements, <strong>elastic applications</strong> can make use of as
much, or as little, throughput as happens to be available</li>
<li>Electronic mail, file transfer, and Web transfers are all elastic
applications.</li>
<li>More throughput always is better</li>
</ul>
<h4 id="timing">Timing</h4>
<ul>
<li>A transport-layer protocol can also provide timing guarantees</li>
<li>An example guarantee might be that every bit that the sender pumps
into the socket arrives at the receiver’s socket no more than 100 ms
later</li>
<li>Long delays in Internet telephony, for example, tend to result in
unnatural pauses in the conversation; in a multiplayer game or virtual
interactive environment, a long delay between taking an action and
seeing the response from the environment (a.k.a, ping. This book so out
of touch it’s ridiculous.)</li>
<li>For non-real-time applications, lower delay is always preferable to
higher delay, but no tight constraint is placed on the end-to-end
delays.</li>
</ul>
<h4 id="security">Security</h4>
<ul>
<li>A transport protocol can provide an application with one or more
security services</li>
<li>For example, in the sending host, a transport protocol can encrypt
all data transmitted by the sending process, and in the receiving host,
the transport-layer protocol can decrypt the data before delivering the
data to the receiving process</li>
<li>Such a service would provide confidentiality between the two
processes, even if the data is somehow observed between sending and
receiving processes.</li>
</ul>
<h3 id="transport-services-provided-by-the-internet">2.1.4 Transport
Services Provided by the Internet</h3>
<ul>
<li>The Internet (and, more generally, TCP/IP networks) makes two
transport protocols available to applications, UDP and TCP.</li>
<li>When you (as an application developer) create a new network
application for the nternet, one of the first decisions you have to make
is whether to use <strong>UDP</strong> or <strong>TCP</strong>.</li>
</ul>
<h4 id="tcp-services">TCP Services</h4>
<ul>
<li>The TCP service model includes a connection-oriented service and a
reliable data transfer service.</li>
<li>When an application invokes TCP as its transport protocol, the
application receives both of these services from TCP</li>
<li><strong>Connection-oriented service</strong>
<ul>
<li>TCP has the client and server exchange transport-layer control
information with each other before the application-level messages begin
to flow.</li>
<li>This so-called “handshaking procedure” alerts the client and server,
allowing them to prepare for an onslaught of packets. After the
handshaking phase, a <strong>TCP connection</strong> is said to exist
between the sockets of the two processes.</li>
<li>The connection is a full-duplex connection in that the two processes
can send messages to each other over the connection at the same
time.</li>
<li>When the application finishes sending messages, it must tear down
the connection.</li>
</ul></li>
<li><strong>Reliable data transfer service</strong>
<ul>
<li>The communicating processes can rely on TCP to deliver all data sent
without error and in the proper order.</li>
<li>When one side of the application passes a stream of bytes into a
socket, it can count on TCP to deliver the same stream of bytes to the
receiving socket, with no missing or duplicate bytes.</li>
<li>TCP also includes a congestion-control mechanism, a service for the
general welfare of the Internet rather than for the direct benefit of
the communicating processes.</li>
<li>The TCP congestion-control mechanism throttles a sending process
(client or server) when the network is congested between sender and
receiver.</li>
</ul></li>
</ul>
<h4 id="udp-services">UDP Services</h4>
<pre><code>* UDP is a no-frills, lightweight transport protocol, providing minimal services.
* UDP is connectionless, so there is no handshaking before the two processes start to communicate.
* UDP provides no guarantee that the message will ever reach the receiving process. Furthermore, messages that do arrive at the receiving process may arrive out of order. This makes it an **unreliable data transfer service**
* UDP does not include a congestion-control mechanism, so the sending side of UDP can pump data into the layer below (the network layer) at any rate it pleases</code></pre>
<h4 id="services-not-provided-by-internet-transport-protocols">Services
Not Provided by Internet Transport Protocols</h4>
<ul>
<li>We have organized transport protocol services along four dimensions:
<ul>
<li>reliable data</li>
<li>transfer</li>
<li>throughput</li>
<li>timing</li>
<li>security.</li>
</ul></li>
<li>Which of these services are provided by TCP and UDP?
<ul>
<li>TCP provides reliable end-to-end data transfer.</li>
<li>TCP can be easily enhanced at the application layer with transport
layer security (TLS) to provide security services</li>
<li>E-mail, remote terminal access, the Web, and file transfer all use
TCP.</li>
<li>These applications have chosen TCP primarily because TCP provides
reliable data transfer, guaranteeing that all data will eventually get
to its destination</li>
</ul></li>
</ul>
<pre><code>Application                 Application-Layer Protocol          Underlying Transport Protocol
Electronic mail             SMTP [RFC 5321]                     TCP
Remote terminal access      Telnet [RFC 854]                    TCP
Web                         HTTP 1.1 [RFC 7230]                 TCP
File transfer               FTP [RFC 959]                       TCP
Streaming multimedia        HTTP (e.g., YouTube), DASH          TCP
Internet telephony          SIP [RFC 3261], RTP [RFC 3550]      UDP or TCP</code></pre>
<ul>
<li>Developers of Internet telephony applications usually prefer to run
their applications over UDP, thereby circumventing TCP’s congestion
control mechanism and packet overheads.</li>
<li>Many firewalls are configured to block (most types of) UDP
traffic</li>
<li>Internet telephony applications are often designed to use TCP as a
backup if UDP communication fails.</li>
</ul>
<h3 id="application-layer-protocols">2.1.5 Application-Layer
Protocols</h3>
<ul>
<li><p>Network processes communicate with each other by sending messages
into sockets.</p></li>
<li><p>But how are these messages structured?</p></li>
<li><p>What are the meanings of the various fields in the
messages?</p></li>
<li><p>When do the processes send the messages?</p></li>
<li><p>The answers to these questions aren’t important, basically, the
Application-Layer Protocols take care of all of these things.</p></li>
<li><p>An <strong>application-layer protocol</strong> defines:</p>
<ul>
<li>The types of messages exchanged, for example, request messages and
response messages</li>
<li>The syntax of the various message types, such as the fields in the
message and how the fields are delineated</li>
<li>The semantics of the fields, that is, the meaning of the information
in the fields</li>
<li>Rules for determining when and how a process sends messages and
responds to messages</li>
</ul></li>
<li><p>Some application-layer protocols are specified in (requests for
comments) RFCs and are therefore in the public domain</p></li>
<li><p>The Web’s application-layer protocol, HTTP (the HyperText
Transfer Protocol [RFC 7230]), is available as an RFC</p></li>
<li><p>If a browser developer follows the rules of the HTTP RFC, the
browser will be able to retrieve Web pages from any Web server that has
also followed the rules of the HTTP RFC</p></li>
<li><p>Many other application-layer protocols are proprietary and
intentionally not available in the public domain. For example, Skype
uses proprietary application-layer protocols.</p></li>
<li><p>The Web is a client-server application that allows users to
obtain documents from Web servers on demand</p></li>
<li><p>The Web application consists of many components:</p>
<ul>
<li>a standard for document formats (that is, HTML)</li>
<li>Web browsers (for example, Chrome and <del>Microsoft Internet
Explorer</del> Firefox)</li>
<li>Web servers (for example, Apache and <del>Microsoft</del> servers)
Windows servers are not real servers IMO</li>
<li>and an application-layer protocol</li>
</ul></li>
<li><p>The Web’s application-layer protocol, HTTP, defines the format
and sequence of messages exchanged between browser and Web
server</p></li>
<li><p>Netflix uses a DASH protocol</p></li>
</ul>
<h3 id="network-applications-covered-in-this-book">2.1.6 Network
Applications Covered in This Book</h3>
<ul>
<li>important applications:
<ul>
<li>The Web</li>
<li>electronic mail</li>
<li>directory service</li>
<li>video streaming</li>
<li>and P2P applications</li>
</ul></li>
</ul>
<h2 id="the-web-and-http">2.2 The Web and HTTP</h2>
<ul>
<li>In the early 1990s, a major new application arrived on the scene–the
World Wide Web [Berners-Lee 1994]</li>
<li>Forms, JavaScript, video, and many other devices enable us to
interact with pages and sites.</li>
</ul>
<h3 id="overview-of-http">2.2.1 Overview of HTTP</h3>
<ul>
<li><p>The <strong>HyperText Transfer Protocol (HTTP)</strong>, the
Web’s application-layer protocol, is at the heart of the Web</p></li>
<li><p>It is defined in [RFC 1945], [RFC 7230] and [RFC 7540]</p></li>
<li><p>HTTP is implemented in two programs:</p>
<ul>
<li>a client program</li>
<li>a server program</li>
</ul></li>
<li><p>The client program and server program, executing on different end
systems, talk to each other by exchanging HTTP messages</p></li>
<li><p>HTTP defines the structure of these messages and how the client
and server exchange the messages</p></li>
<li><p>A <strong>Web page</strong> (also called a document) consists of
objects</p></li>
<li><p>An object is simply a file–such as an <strong>HTML</strong> file,
a <strong>JPEG</strong> image, a Javascrpt file, a <strong>CSS</strong>
style sheet file, or a video clip–that is addressable by a single
<strong>URL</strong></p></li>
<li><p>Most Web pages consist of a base <strong>HTML file</strong> and
several referenced objects</p></li>
<li><p>Each URL has two components:</p>
<ul>
<li>the hostname of the server</li>
<li>object’s path name</li>
</ul></li>
<li><p>In the URL:
<code>http://www.someSchool.edu/someDepartment/picture.gif</code></p>
<ul>
<li>hostname = <code>www.someSchool.edu</code></li>
<li>path name = <code>/someDepartment/picture.gif</code></li>
</ul></li>
<li><p>Because <strong>Web browsers</strong> implement the client side
of HTTP, in the context of the Web, we will use the words
<code>browser</code> and <code>client</code> interchangeably</p></li>
<li><p><strong>Web servers</strong>, which implement the server side of
HTTP, house Web objects, each addressable by a URL</p></li>
<li><p>HTTP request messages for the objects in the page to the
server</p></li>
<li><p>HTTP uses TCP as its underlying transport protocol (rather than
running on top of UDP)</p></li>
<li><p>HTTP Process</p>
<ul>
<li>The HTTP client first initiates a TCP connection with the
server</li>
<li>Once the connection is established, the browser and the server
processes access TCP through their socket interfaces</li>
<li>The client sends HTTP request messages into its socket interface and
receives HTTP response messages from its socket interface</li>
<li>Similarly, the HTTP server receives request messages from its socket
interface and sends response messages into its socket interface</li>
<li>Once the client sends a message into its socket interface, the
message is out of the client’s hands and is â€œin the hands” of TCP</li>
</ul></li>
<li><p>The server sends requested files to clients without storing any
state information about the client</p></li>
<li><p>Because an HTTP server maintains no information about the
clients, HTTP is said to be a <strong>stateless
protocol</strong></p></li>
<li><p>Web server is always on, with a fixed IP address, and it services
requests from potentially millions of different browsers.</p></li>
<li><p>The original version of HTTP is called HTTP/1.0 and dates back to
the early 1990’s [RFC 1945]</p></li>
<li><p>As of 2020, the majority of HTTP transactions take place over
HTTP/1.1 [RFC 7230]</p></li>
<li><p>However, increasingly browsers and Web servers also support a new
version of HTTP called HTTP/2 [RFC 7540]</p></li>
</ul>
<h3 id="non-persistent-and-persistent-connections">2.2.2 Non-Persistent
and Persistent Connections</h3>
<ul>
<li>Should each request/response pair be sent over a separate TCP
connection? If so, this is a <strong>non-persistent
connection</strong></li>
<li>Should all of the requests and their corresponding responses be sent
over the same TCP connection? If so, this is a <strong>persistent
connection</strong></li>
<li>Although HTTP uses persistent connections in its default mode, HTTP
clients and servers can be configured to use non-persistent connections
instead</li>
</ul>
<h4 id="http-with-non-persistent-connections">HTTP with Non-Persistent
Connections</h4>
<ul>
<li>Suppose the page consists of a base HTML file and 10 JPEG images,
and that all 11 of these objects reside on the same server.</li>
<li>Suppose the URL for the base HTML file is
<code>http://www.someSchool.edu/someDepartment/home.index</code></li>
<li>Here is what happens:
<ol type="1">
<li>The HTTP client process initiates a TCP connection to the server
<code>www.someSchool.edu</code> on port number 80, which is the default
port number for HTTP. Associated with the TCP connection, there will be
a socket at the client and a socket at the server.</li>
<li>The HTTP client sends an HTTP request message to the server via its
socket. The request message includes the path name
<code>/someDepartment/home.index</code></li>
<li>The HTTP server process receives the request message via its socket,
retrieves the object <code>/someDepartment/home.index</code> from its
storage (RAM or disk), encapsulates the object in an HTTP response
message, and sends the response message to the client via its
socket</li>
<li>The HTTP server process tells TCP to close the TCP connection. (But
TCP doesn’t actually terminate the connection until it knows for sure
that the client has received the response message intact.)</li>
<li>The HTTP client receives the response message. The TCP connection
terminates. The message indicates that the encapsulated object is an
HTML file. The client extracts the file from the response message,
examines the HTML file, and finds references to the 10 JPEG
objects.</li>
<li>The first four steps are then repeated for each of the referenced
JPEG objects.</li>
</ol></li>
<li>The steps above illustrate the use of non-persistent connections,
where each TCP connection is closed after the server sends the
object–the connection does not persist for other objects</li>
<li>HTTP/1.0 employes non-persistent TCP connections. Note that each
non-persistent TCP connection transports exactly one request message and
one response message</li>
<li><strong>round-trip time (RTT)</strong>, is the time it takes for a
small packet to travel from client to server and then back to the
client</li>
<li>The <strong>RTT</strong> includes packet-propagation delays,
packetqueuing delays in intermediate routers and switches, and
packet-processing delays</li>
<li>This causes the browser to initiate a TCP connection between the
browser and the Web server</li>
<li>This involves a â€œthree-way handshake”
<ul>
<li>the client sends a small TCP segment to the server</li>
<li>the server acknowledges and responds with a small TCP segment</li>
<li>the client acknowledges back to the server</li>
</ul></li>
<li>The first two parts of the three-way handshake take one RTT</li>
<li>the client sends the HTTP request message combined with the third
part of the three-way handshake (the acknowledgment) into the TCP
connection</li>
<li>This HTTP request/response eats up another RTT. Thus, roughly, the
total response time is two RTTs plus the transmission time at the server
of the HTML file</li>
</ul>
<h4 id="http-with-persistent-connections">HTTP with Persistent
Connections</h4>
<ul>
<li>Non-persistent connections have some shortcomings
<ul>
<li>a brand-new connection must be established and maintained for
<code>each requested object</code></li>
<li>For each of these connections, TCP buffers must be allocated and TCP
variables must be kept in both the client and server</li>
<li>This can place a significant burden on the Web server, which may be
serving requests from hundreds of different clients simultaneously</li>
<li>each object suffers a delivery delay of two RTTs–one RTT to
establish the TCP connection and one RTT to request and receive an
object</li>
</ul></li>
<li>With HTTP/1.1 persistent connections, the server leaves the TCP
connection open after sending a response</li>
<li>Subsequent requests and responses between the same client and server
can be sent over the same connection</li>
<li>In particular, an entire Web page (in the example above, the base
HTML file and the 10 images) can be sent over a single persistent TCP
connection</li>
<li>Moreover, multiple Web pages residing on the same server can be sent
from the server to the same client over a single persistent TCP
connection</li>
<li>Typically, the HTTP server closes a connection when it isn’t used
for a certain time (a configurable timeout interval)</li>
<li>When the server receives the back-to-back requests, it sends the
objects back-to-back</li>
<li>The default mode of HTTP uses persistent connections with
pipelining.</li>
</ul>
<h3 id="http-message-format">2.2.3 HTTP Message Format</h3>
<ul>
<li>The HTTP specifications [RFC 1945; RFC 7230; RFC 7540] include the
definitions of the HTTP message formats.</li>
<li>There are two types of HTTP messages
<ul>
<li><strong>request messages</strong></li>
<li><strong>response messages</strong></li>
</ul></li>
</ul>
<h4 id="http-request-message">HTTP Request Message</h4>
<pre><code>Below we provide a typical HTTP request message:
GET /somedir/page.html HTTP/1.1
Host: www.someschool.edu
Connection: close
User-agent: Mozilla/5.0
Accept-language: fr</code></pre>
<ul>
<li>The message is written in ordinary ASCII text, i.e. it is human
readable</li>
<li>The message consists of five lines, each followed by a carriage
return and a line feed</li>
<li>The last line is followed by an additional carriage return and line
feed.</li>
<li>The first line of an HTTP request message is called the
<strong>request line</strong></li>
<li>The subsequent lines are called the <strong>header
lines</strong></li>
<li>The request line has three fields:
<ul>
<li>method field</li>
<li>URL field</li>
<li>HTTP version field</li>
</ul></li>
<li>The method field can take several different values including:
<ul>
<li>GET</li>
<li>POST</li>
<li>HEAD</li>
<li>PUT</li>
<li>DELETE.</li>
</ul></li>
<li>The great majority of HTTP request messages use the GET method.</li>
<li>The GET method is used when the browser requests an object, with the
requested object identified in the URL field</li>
<li>The header line <code>Host: www.someschool.edu</code> specifies the
host on which the object resides</li>
<li>By including the <code>Connection: close</code> header line, the
browser is telling the server that it doesn’t want to bother with
persistent connections</li>
<li>The <code>User-agent:</code> header line specifies the user agent
i.e. the browser type that is making the request to the server</li>
<li>The <code>Accept-language:</code> header indicates that the user
prefers to receive a French version of the object, if such an object
exists on the server; otherwise, the server should send its default
version</li>
<li>The entity body is empty with the GET method, but is used with the
POST method</li>
<li>An HTTP client often uses the POST method when the user fills out a
form i.e. searching something on Google</li>
<li>With a POST message, the user is still requesting a Web page from
the server, but the specific contents of the Web page depend on what the
user entered into the form fields</li>
<li>If the value of the method field is POST, then the entity body
contains what the user entered into the form fields</li>
<li>The HEAD method is similar to the GET method. When a server receives
a request with the HEAD method, it responds with an HTTP message but it
leaves out the requested object</li>
<li>Application developers often use the HEAD method for debugging</li>
<li>The PUT method is often used in conjunction with Web publishing
tools</li>
<li>The PUT method is also used by applications that need to upload
objects to Web servers</li>
<li>The DELETE method allows a user, or an application, to delete an
object on a Web server</li>
</ul>
<h4 id="http-response-message">HTTP Response Message</h4>
<pre><code>HTTP/1.1 200 OK
Connection: close
Date: Tue, 18 Aug 2015 15:44:04 GMT
Server: Apache/2.2.3 (CentOS)
Last-Modified: Tue, 18 Aug 2015 15:11:03 GMT
Content-Length: 6821
Content-Type: text/html

(data data data data data ...)</code></pre>
<ul>
<li><p>The HTTP Response Message has three sections:</p>
<ul>
<li>an initial status line</li>
<li>six header lines</li>
<li>and then the entity body</li>
</ul></li>
<li><p>The entity body contains the requested object itself (represented
by <code>data data data data data ...</code>)</p></li>
<li><p>The status line has three fields:</p>
<ul>
<li>the protocol version field</li>
<li>a status code</li>
<li>and a corresponding status message.</li>
</ul></li>
<li><p>In this example, the status line indicates that the server is
using HTTP/1.1 and that everything is OK</p></li>
<li><p>The server uses the <code>Connection: close</code> header line to
tell the client that it is going to close the TCP connection after
sending the message.</p></li>
<li><p>The <code>Date:</code> header line indicates the time and date
when the HTTP response was created and sent by the server</p></li>
<li><p>The <code>Server:</code> header line indicates that the message
was generated by an Apache Web server; it is analogous to the
<code>User-agent:</code> header line in the HTTP request
message</p></li>
<li><p>The <code>Last-Modified:</code> header line indicates the time
and date when the object was created or last modified.</p></li>
<li><p>The <code>Content-Length:</code> header line indicates the number
of bytes in the object being sent.</p></li>
<li><p>Some common status codes and associated phrases include:</p>
<ul>
<li><code>200 OK:</code> Request succeeded and the information is
returned in the response.</li>
<li><code>301 Moved Permanently:</code> Requested object has been
permanently moved; the new URL is specified in Location: header of the
response message. The client software will automatically retrieve the
new URL.</li>
<li><code>400 Bad Request:</code> This is a generic error code
indicating that the request could not be understood by the server.</li>
<li><code>404 Not Found:</code> The requested document does not exist on
this server.</li>
<li><code>505 HTTP Version Not Supported:</code> The requested HTTP
protocol version is not supported by the server.</li>
</ul></li>
</ul>
<p><strong>Q:</strong> How does a browser decide which header lines to
include in a request message?</p>
<p><strong>A:</strong> A browser will generate header lines as a
function of the browser type and version, the user configuration of the
browser and whether the browser currently has a cached, but possibly
out-of-date, version of the object.</p>
<p><strong>Q:</strong> How does a Web server decide which header lines
to include in a response message?</p>
<p><strong>A:</strong> Web servers behave similarly: There are different
products, versions, and configurations, all of which influence which
header lines are included in response messages.</p>
<h3 id="user-server-interaction-cookies">2.2.4 User-Server Interaction:
Cookies</h3>
<ul>
<li>An HTTP server is stateless</li>
<li>This simplifies server design and has permitted engineers to develop
high-performance Web servers that can handle thousands of simultaneous
TCP connections</li>
<li>However, it is often desirable for a Web site to identify users</li>
<li>For these purposes, HTTP uses cookies.</li>
<li>Cookies, defined in [RFC 6265], allow sites to keep track of
users.</li>
<li>Most major commercial Web sites use cookies today</li>
<li>The first time a user visits a site, the user can provide a user
identification (possibly his or her name)</li>
<li>During the subsequent sessions, the browser passes a cookie header
to the server, thereby identifying the user to the server</li>
<li>Cookies can thus be used to create a user session layer on top of
stateless HTTP</li>
<li>For example, when a user logs in to a Web-based e-mail application
(such as Hotmail), the browser sends cookie information to the server,
permitting the server to identify the user throughout the user’s session
with the application</li>
<li>Web site can learn a lot about a user through cookies and
potentially sell this information to a third party</li>
</ul>
<h3 id="web-caching">2.2.5 Web Caching</h3>
<ul>
<li>A <strong>Web cache</strong>/<strong>proxy server</strong>is a
network entity that satisfies HTTP requests on the behalf of an origin
Web server</li>
<li>The Web cache has its own disk storage and keeps copies of recently
requested objects in this storage</li>
<li>Suppose a browser is requesting the object
<code>http://www.someschool.edu/campus.gif</code>
<ol type="1">
<li>The browser establishes a TCP connection to the Web cache and sends
an HTTP request for the object to the Web cache.</li>
<li>The Web cache checks to see if it has a copy of the object stored
locally. If it does, the Web cache returns the object within an HTTP
response message to the client browser.</li>
<li>If the Web cache does not have the object, the Web cache opens a TCP
connection to the origin server, that is, to
<code>www.someschool.edu</code>. The Web cache then sends an HTTP
request for the object into the cache-to-server TCP connection. After
receiving this request, the origin server sends the object within an
HTTP response to the Web cache.</li>
<li>When the Web cache receives the object, it stores a copy in its
local storage and sends a copy, within an HTTP response message, to the
client browser (over the existing TCP connection between the client
browser and the Web cache).</li>
</ol></li>
<li>Note that a cache is both a server and a client at the same time
<ul>
<li>When it receives requests from and sends responses to a browser, it
is a server</li>
<li>When it sends requests to and receives responses from an origin
server, it is a client</li>
</ul></li>
<li>Typically a Web cache is purchased and installed by an ISP</li>
<li>Web caching has seen deployment in the Internet for two reasons.
<ul>
<li>First, a Web cache can substantially reduce the response time for a
client request, particularly if the bottleneck bandwidth between the
client and the origin server is much less than the bottleneck bandwidth
between the client and the cache</li>
<li>Second, as we will soon illustrate with an example, Web caches can
substantially reduce traffic on an institution’s access link to the
Internet. By reducing traffic, the institution (for example, a company
or a university) does not have to upgrade bandwidth as quickly, thereby
reducing costs</li>
<li>Furthermore, Web caches can substantially reduce Web traffic in the
Internet as a whole, thereby improving performance for all
applications</li>
</ul></li>
<li>Examples:</li>
<li>The traffic intensity on the LAN
<ul>
<li><code>(15 requests/sec) # (1 Mbits/request)/(100 Mbps) = 0.15</code></li>
</ul></li>
<li>Whereas the traffic intensity on the access link (from the Internet
router to institution router) is
<ul>
<li><code>(15 requests/sec) # (1 Mbits/request)/(15 Mbps) = 1</code></li>
</ul></li>
<li>A traffic intensity of 0.15 on a LAN typically results in, at most,
tens of milliseconds of delay; hence, we can neglect the LAN delay<br />
</li>
<li>However, as discussed earlier, as the traffic intensity approaches
1, the delay on a link becomes very large and grows without bound ( it
diverges )</li>
<li>Thus, the average response time to satisfy requests is going to be
on the order of minutes, if not more, which is unacceptable for the
institution’s users.</li>
<li>Through the use of <strong>Content Distribution Networks
(CDNs)</strong>, Web caches are increasingly playing an important role
in the Internet</li>
</ul>
<h4 id="the-conditional-get">The Conditional GET</h4>
<ul>
<li>HTTP has a mechanism that allows a cache to verify that its objects
are up to date</li>
<li>This mechanism is called the <strong>conditional GET</strong> [RFC
7232]</li>
</ul>
<h3 id="http2">2.2.6 HTTP/2</h3>
<ul>
<li><p>HTTP/2 [RFC 7540], standardized in 2015, was the first new
version of HTTP since HTTP/1.1, which was standardized in 1997</p></li>
<li><p>Since standardization, HTTP/2 has taken off, with over 40% of the
top 10 million websites supporting HTTP/2 in 2020 [W3Techs]</p></li>
<li><p>The primary goals for HTTP/2 are to reduce perceived latency by
enabling request and response multiplexing over a single TCP connection,
provide request prioritization and server push, and provide efficient
compression of HTTP header fields</p></li>
<li><p>HTTP/2 does not change HTTP methods, status codes, URLs, or
header fields</p></li>
<li><p>HTTP/2 changes how the data is formatted and transported between
the client and server</p></li>
<li><p>developers of Web browsers quickly discovered that sending all
the objects in a Web page over a single TCP connection has a
<strong>Head of Line (HOL)</strong> blocking problem</p></li>
<li><p>Suppose there is a Web page that includes an HTML base page, a
large video clip near the top of Web page, and many small objects below
the video</p></li>
<li><p>Suppose there is a low-to-medium speed bottleneck link (for
example, a low-speed wireless link) on the path between server and
client</p></li>
<li><p>Using a single TCP connection, the video clip will take a long
time to pass through the bottleneck link, while the small objects are
delayed as they wait behind the video clip; that is, the video clip at
the head of the line blocks the small objects behind it</p></li>
<li><p>HTTP/1.1 browsers typically work around this problem by opening
multiple parallel TCP connections, thereby having objects in the same
web page sent in parallel to the browser</p></li>
<li><p><strong>TCP congestion control</strong>, discussed in detail in
Chapter 3, also provides browsers an unintended incentive to use
multiple parallel TCP connections rather than a single persistent
connection</p></li>
<li><p>TCP congestion control aims to give each TCP connection sharing a
bottleneck link an equal share of the available bandwidth of that link;
so if there are <code>n</code> TCP connections operating over a
bottleneck link, then each connection approximately gets
<code>1/nth</code> of the bandwidth</p></li>
<li><p>By opening multiple parallel TCP connections to transport a
single Web page, the browser can “cheat” and grab a larger portion of
the link bandwidth</p></li>
<li><p>Many HTTP/1.1 browsers open up to six parallel TCP connections
not only to circumvent HOL blocking but also to obtain more
bandwidth</p></li>
</ul>
<h4 id="http2-framing">HTTP/2 Framing</h4>
<ul>
<li>The HTTP/2 solution for HOL blocking is to break each message into
small frames, and interleave the request and response messages on the
same TCP connection</li>
<li>The ability to break down an HTTP message into independent frames,
interleave them, and then reassemble them on the other end is the single
most important enhancement of HTTP/2</li>
<li>The framing is done by the framing sub-layer of the HTTP/2
protocol.</li>
<li>When a server wants to send an HTTP response, the response is
processed by the framing sub-layer, where it is broken down into
frames.</li>
<li>In addition to breaking down each HTTP message into independent
frames, the framing sublayer also binary encodes the frames.</li>
<li>Binary protocols are more efficient to parse, lead to slightly
smaller frames, and are less error-prone.</li>
</ul>
<h4 id="response-message-prioritization-and-server-pushing">Response
Message Prioritization and Server Pushing</h4>
<ul>
<li><strong>Message prioritization</strong> allows developers to
customize the relative priority of requests to better optimize
application performance</li>
<li>When a client sends concurrent requests to a server, it can
prioritize the responses it is requesting by assigning a weight between
1 and 256 to each message. The higher number indicates higher
priority</li>
<li>In addition to this, the client also states each message’s
dependency on other messages by specifying the ID of the message on
which it depends</li>
<li>Another feature of HTTP/2 is the ability for a server to send
multiple responses for a single client request</li>
<li>In addition to the response to the original request, the server can
push additional objects to the client, without the client having to
request each one</li>
</ul>
<h4 id="http3">HTTP/3</h4>
<ul>
<li>QUIC, discussed in Chapter 3, is a new â€œtransport” protocol that
is implemented in the application layer over the bare-bones UDP
protocol</li>
<li>QUIC has several features that are desirable for HTTP, such as
message multiplexing (interleaving), per-stream flow control, and
low-latency connection establishment</li>
</ul>
<h2 id="electronic-mail-in-the-internet">2.3 Electronic Mail in the
Internet</h2>
<ul>
<li>Electronic mail has been around since the beginning of the Internet.
It was the most popular application when the Internet was in its infancy
[Segaller 1998]</li>
<li>In contrast with postal mail, electronic mail is fast, easy to
distribute, and inexpensive</li>
<li>Modern e-mail has many powerful features, including messages with
attachments, hyperlinks, HTML-formatted text, and embedded photos</li>
<li>e-mail has three major components:
<ul>
<li><strong>user agents</strong></li>
<li><strong>mail servers</strong></li>
<li><strong>Simple Mail Transfer Protocol (SMTP)</strong></li>
</ul></li>
<li>User agents allow users to read, reply to, forward, save, and
compose messages.</li>
<li>Examples of user agents for e-mail include Microsoft Outlook, Apple
Mail, Web-based Gmail, the Gmail App running in a smartphone, and so
on</li>
<li>Each recipient, has a mailbox located in one of the mail
servers</li>
<li>A typical message starts its journey in the sender’s user agent,
then travels to the sender’s mail server, and then travels to the
recipient’s mail server, where it is deposited in the recipient’s
mailbox</li>
<li>If Alice’s server cannot deliver mail to Bob’s server, Alice’s
server holds the message in a <strong>message queue</strong> and
attempts to transfer the message later</li>
<li><strong>SMTP</strong> is the principal application-layer protocol
for Internet electronic mail. It uses the reliable data transfer service
of TCP to transfer mail from the sender’s mail server to the recipient’s
mail server.</li>
<li>As with most application-layer protocols, SMTP has two sides:
<ul>
<li>a client side, which executes on the sender’s mail server</li>
<li>and a server side, which executes on the recipient’s mail
server</li>
</ul></li>
<li>Both the client and server sides of SMTP run on every mail
server</li>
<li>When a mail server sends mail to other mail servers, it acts as an
SMTP client.</li>
<li>When a mail server receives mail from other mail servers, it acts as
an SMTP server.</li>
</ul>
<h3 id="smtp">2.3.1 SMTP</h3>
<ul>
<li>SMTP transfers messages from senders’ mail servers to the
recipients’ mail servers.</li>
<li>SMTP is much older than HTTP. (The original SMTP RFC dates back to
1982, and SMTP was around long before that.)</li>
<li>Although SMTP has numerous wonderful qualities, it is nevertheless a
legacy technology that possesses certain archaic characteristics</li>
<li>For example, it restricts the body (not just the headers) of all
mail messages to simple 7-bit ASCII.</li>
<li>This restriction made sense in the early 1980s when transmission
capacity was scarce and no one was e-mailing large attachments or large
image, audio, or video files</li>
<li>Today, the 7-bit ASCII restriction is a bit of a pain. It requires
binary multimedia data to be encoded to ASCII before being sent over
SMTP; and it requires the corresponding ASCII message to be decoded back
to binary after SMTP transport</li>
<li>HTTP does not require multimedia data to be ASCII encoded before
transfer.</li>
<li>Suppose Alice wants to send Bob a simple ASCII message.
<ol type="1">
<li>Alice invokes her user agent for e-mail, provides Bob’s e-mail
address (i.e., <code>bob@someschool.edu</code>), composes a message, and
instructs the user agent to send the message</li>
<li>Alice’s user agent sends the message to her mail server, where it is
placed in a message queue.</li>
<li>The client side of SMTP, running on Alice’s mail server, sees the
message in the message queue. It opens a TCP connection to an SMTP
server, running on Bob’s mail server.</li>
<li>After some initial SMTP handshaking, the SMTP client sends Alice’s
message into the TCP connection.</li>
<li>At Bob’s mail server, the server side of SMTP receives the message.
Bob’s mail server then places the message in Bob’s mailbox.</li>
<li>Bob invokes his user agent to read the message at his
convenience.</li>
</ol></li>
<li>It is important to observe that SMTP does not normally use
intermediate mail servers for sending mail, even when the two mail
servers are located at opposite ends of the world</li>
<li>If Alice’s server is in Hong Kong and Bob’s server is in St. Louis,
the TCP connection is a direct connection between the Hong Kong and
St. Louis servers</li>
<li>In particular, if Bob’s mail server is down, the message remains in
Alice’s mail server and waits for a new attempt–the message does not get
placed in some intermediate mail server.</li>
</ul>
<h4
id="how-does-smtp-transfer-a-message-from-a-sending-mail-server-to-a-receiving-mail-server">How
does SMTP transfer a message from a sending mail server to a receiving
mail server?</h4>
<ul>
<li><p>The client SMTP (running on the sending mail server host) has TCP
establish a connection to port 25 at the server SMTP (running on the
receiving mail server host)</p></li>
<li><p>If the server is down, the client tries again later</p></li>
<li><p>Once this connection is established, the server and client
perform some application-layer handshaking.</p></li>
<li><p>Similar to how humans would introduce themselves before
transferring information from one to another, SMTP clients and servers
introduce themselves before transferring information</p></li>
<li><p>During this SMTP handshaking phase, the SMTP client indicates the
e-mail address of the sender (the person who generated the message) and
the e-mail address of the recipient</p></li>
<li><p>Once the SMTP client and server have introduced themselves to
each other, the client sends the message</p></li>
<li><p>SMTP can count on the reliable data transfer service of TCP to
get the message to the server without errors</p></li>
<li><p>The client then repeats this process over the same TCP connection
if it has other messages to send to the server; otherwise, it instructs
TCP to close the connection</p></li>
<li><p>Suppose the hostname of the client is <code>crepes.fr</code> and
the hostname of the server is <code>hambuger.edu</code></p></li>
<li><p>The ASCII text lines prefaced with <code>C:</code> are exactly
the lines the client sends into its TCP socket, and the ASCII text lines
prefaced with <code>S:</code> are exactly the lines the server sends
into its TCP socket.</p></li>
<li><p>This is an an example transcript of messages exchanged between an
SMTP client (C) and an SMTP server (S)</p></li>
</ul>
<pre><code>S: 220 hamburger.edu
C: HELO crepes.fr
S: 250 Hello crepes.fr, pleased to meet you
C: MAIL FROM: &lt;alice@crepes.fr&gt;
S: 250 alice@crepes.fr ... Sender ok
C: RCPT TO: &lt;bob@hamburger.edu&gt;
S: 250 bob@hamburger.edu ... Recipient ok
C: DATA
S: 354 Enter mail, end with &quot;.&quot; on a line by itself
C: Do you like ketchup?
C: How about pickles?
C: .
S: 250 Message accepted for delivery
C: QUIT
S: 221 hamburger.edu closing connection</code></pre>
<ul>
<li>In the example above, the client sends a message
(â€œ<code>Do you like ketchup? How about pickles?"</code>) from mail
server <code>crepes.fr</code> to mail server
<code>hamburger.edu</code></li>
<li>As part of the dialogue, the client issued five commands:
<ul>
<li>HELO (an abbreviation for HELLO)</li>
<li>MAIL FROM</li>
<li>RCPT TO</li>
<li>DATA</li>
<li>QUIT</li>
</ul></li>
<li>In ASCII , each message ends with <code>CRLF</code>.
<code>CRLF</code>, where <code>CR</code> and <code>LF</code> stand for
carriage return and line feed, respectively</li>
<li>The server issues replies to each command, with each reply having a
reply code and some (optional) English-language explanation</li>
<li>SMTP uses persistent connections:
<ul>
<li>If the sending mail server has several messages to send to the same
receiving mail server, it can send all of the messages over the same TCP
connection</li>
<li>For each message, the client begins the process with a new
<code>MAIL FROM: crepes.fr</code>, designates the end of message with an
isolated period, and issues <code>QUIT</code> only after all messages
have been sent.</li>
</ul></li>
<li>It is highly recommended that you use Telnet to carry out a direct
dialogue with an SMTP server
<ul>
<li>you can do this by running the command
<code>telnet serverName 25</code></li>
<li>When you do this, you are simply establishing a TCP connection
between your local host and the mail server.</li>
<li>After typing this line, you should immediately receive the
<code>220</code> reply from the server</li>
<li>Then issue the SMTP commands <code>HELO</code>, <code>MAIL</code>
<code>FROM</code>, <code>RCPT</code> <code>TO</code>, <code>DATA</code>,
<code>CRLF</code>.</li>
<li><code>CRLF</code>, and <code>QUIT</code> at the appropriate
times.</li>
</ul></li>
</ul>
<h3 id="mail-message-formats">2.3.2 Mail Message Formats</h3>
<ul>
<li><p>As with HTTP, each header line contains readable text, consisting
of a keyword followed by a colon followed by a value</p></li>
<li><p>Some of the keywords are required and others are
optional</p></li>
<li><p>Every header must have a <code>From:</code> header line and a
<code>To:</code> header line</p></li>
<li><p>A header may include a <code>Subject:</code> header line as well
as other optional header lines</p></li>
<li><p>It is important to note that these header lines are different
from the SMTP commands, even though they contain some of the same words,
such as <code>From:</code> and <code>To:</code></p></li>
<li><p>The commands in the previous section were part of the SMTP
handshaking protocol</p></li>
<li><p>The header lines examined in this section are part of the mail
message itself</p></li>
<li><p>A typical message header looks like this:</p></li>
</ul>
<pre><code>From: alice@crepes.fr
To: bob@hamburger.edu
Subject: Searching for the meaning of life.</code></pre>
<ul>
<li>I think we all know what an email looks like.</li>
</ul>
<h3 id="mail-access-protocols">2.3.3 Mail Access Protocols</h3>
<ul>
<li>Once SMTP delivers the message from Alice’s mail server to Bob’s
mail server, the message is placed in Bob’s mailbox.</li>
<li>Given that Bob (the recipient) executes his user agent on his local
host (e.g., smartphone or PC), it is natural to consider placing a mail
server on his local host as well</li>
<li>With this approach, Alice’s mail server would dialogue directly with
Bob’s PC</li>
<li>There is a problem with this approach, however.</li>
<li>A mail server manages mailboxes and runs the client and server sides
of SMTP.</li>
<li>If Bob’s mail server were to reside on his local host, then Bob’s
host would have to remain always on, and connected to the Internet, in
order to receive new mail, which can arrive at any time (Yes, no shit.
This is how servers work.)</li>
<li>Typically, most users run a user agent on the local host but
accesses its mailbox stored on an always-on shared mail server. This
mail server is shared with among other users.</li>
<li>Let’s consider the path an e-mail message takes when it is sent from
Alice to Bob</li>
<li>The e-mail message needs to be deposited in Bob’s mail server.</li>
<li>This could be done simply by having Alice’s user agent send the
message directly to Bob’s mail server.</li>
<li>However, typically the sender’s user agent does not dialogue
directly with the recipient’s mail server</li>
<li>Instead, Alice’s user agent uses SMTP or HTTP to deliver the e-mail
message into her mail server, then Alice’s mail server uses SMTP (as an
SMTP client) to relay the e-mail message to Bob’s mail server</li>
</ul>
<h4 id="why-a-two-step-procedure">Why a two step procedure?</h4>
<ul>
<li>If we sent the message directly to Bob’s server while his computer
is not on, the email would have nowhere to go. By first deposting the
the email in her own server, Alice’s mail server can reattempt to send
the mail if it does not go through, until it finally does go
through.</li>
<li>How does a recipient like Bob, running a user agent on his local
host , obtain his messages, which are sitting in a mail server?</li>
<li>Bob’s user agent can’t use SMTP to obtain the messages because
obtaining the messages is a pull operation, SMTP is a push protocol and
cannot do this.</li>
<li>Today, there are two common ways for Bob to retrieve his e-mail:
<ul>
<li>If Bob is using Web-based e-mail or a smartphone app (such as
Gmail), then the user agent will use HTTP to retrieve Bob’s e-mail. This
case requires Bob’s mail server to have an HTTP interface as well as an
SMTP interface (to communicate with Alice’s mail server)</li>
<li>The alternative is typically used with mail clients such as
Microsoft Outlook, the <strong>Internet Mail Access Protocol
(IMAP)</strong></li>
</ul></li>
<li>Both the <strong>HTTP</strong> and <strong>IMAP</strong> approaches
allow Bob to manage folders, maintained in Bob’s mail server</li>
</ul>
<h2 id="dns---the-internets-directory-service">2.4 DNS - The Internet’s
Directory Service</h2>
<ul>
<li>One identifier for a host is its <strong>hostname</strong>,
i.e. <code>www.facebook.com</code></li>
<li><strong>Hostnames</strong> are mnemonic and preferred over using
just a raw IP address. It is also a bit safer security wise to use
hostnames, so that your website URL isn’t displaying your server’s IP
address to every user that visits the website.</li>
<li>While hostnames are nice, they do not tell us, (or more importantly,
the computer) much about that website. Perhaps the URL ends in a country
code such as <code>.fr</code> or <code>.io</code>. This however, still
does not provide us much information about that website.</li>
<li>For these reasons, hosts are also identified by <strong>IP
addresses</strong></li>
</ul>
<h3 id="services-provided-by-dns">2.4.1 Services Provided by DNS</h3>
<ul>
<li><p>there are two ways to identify a host:</p>
<ul>
<li>by its hostname</li>
<li>by its IP address</li>
</ul></li>
<li><p>While human’s will prefer hostnames, a computer prefers IP
addresses.</p></li>
<li><p>This task can be resolved through the Internet’s <strong>domain
name system (DNS)</strong></p></li>
<li><p>The DNS is:</p>
<ol type="1">
<li>distributed database implemented in a hierarchy of <strong>DNS
servers</strong></li>
<li>an application-layer protocol that allows hosts to query the
distributed database</li>
</ol></li>
<li><p>DNS servers are often UNIX machines running <strong>Berkeley
Internet Name Domain (BIND)</strong> software</p></li>
<li><p>DNS is commonly employed by other application-layer protocols,
including HTTP and SMTP, to translate user-supplied hostnames to IP
addresses</p></li>
<li><p>Example:</p>
<ul>
<li>consider what happens when a browser (that is, an HTTP client),
running on some user’s host, requests the URL
<code>www.someschool.edu/index.html</code>.</li>
<li>In order for the user’s host to be able to send an HTTP request
message to the Web server <code>www.someschool.edu</code>, the user’s
host must first obtain the IP address of
<code>www.someschool.edu</code></li>
</ul></li>
<li><p>This is done as follows:</p>
<ol type="1">
<li>The same user machine runs the client side of the DNS
application.</li>
<li>The browser extracts the hostname, www.someschool.edu, from the URL
and passes the hostname to the client side of the DNS application.</li>
<li>The DNS client sends a query containing the hostname to a DNS
server.</li>
<li>The DNS client eventually receives a reply, which includes the IP
address for the hostname.</li>
<li>Once the browser receives the IP address from DNS, it can initiate a
TCP connection to the HTTP server process located at port 80 at that IP
address.</li>
</ol></li>
<li><p>We see from this example that DNS adds an additional delay which
is sometimes substantial to the Internet applications that use
it.</p></li>
<li><p>However, in most cases, the desired IP address is often cached in
a â€œnearby” DNS server, which helps to reduce DNS network traffic as
well as the average DNS delay</p></li>
<li><p>DNS provides a few other important services in addition to
translating hostnames to IP addresses:</p>
<ul>
<li><strong>Host aliasing</strong>. A host with a complicated hostname
can have one or more alias names. (i.e. the URL
<code>relay1.west-coast.enterprise.com</code> being aliased to
<code>enterprise.com</code> and/or <code>www.enterprise.com</code>. In
this case, the hostname <code>relay1.west-coast.enterprise.com</code> is
said to be a <strong>canonical hostname</strong>. The DNS can be invoked
by an application to obtain the <strong>canonical hostname</strong> for
a supplied alias hostname as well as the IP address of the host</li>
<li><strong>Mail server aliasing</strong>. It is highly desirable to
make e-mail addresses be mnemonic.If there were no <strong>Mail serer
aliasing</strong>, we would have compicated email addresses… like
<code>bob@relay1.west-coast.yahoo.com</code> for example. Or even worse,
raw IP addresses as hostnames.</li>
<li><strong>Load distribution</strong>. DNS is also used to perform load
distribution among replicated servers, such as replicated Web
servers</li>
<li>Busy sites, such as <code>cnn.com</code>, are replicated over
multiple servers, with each server running on a different end system and
each having a different IP address</li>
<li>For replicated Web servers, a set of IP addresses is thus associated
with one alias hostname</li>
<li>The DNS database contains this set of IP addresses</li>
<li>When clients make a DNS query for a name mapped to a set of
addresses, the server responds with the entire set of IP addresses, but
rotates the ordering of the addresses within each reply</li>
<li>Because a client typically sends its HTTP request message to the IP
address that is listed first in the set, DNS rotation distributes the
traffic among the replicated servers</li>
<li>DNS rotation is also used for e-mail so that multiple mail servers
can have the same alias name</li>
</ul></li>
</ul>
<h3 id="overview-of-how-dns-works">2.4.2 Overview of How DNS Works</h3>
<ul>
<li>Suppose that some application (such as a Web browser or a mail
client) running in a user’s host needs to translate a hostname to an IP
address</li>
<li>The application will invoke the client side of DNS, specifying the
hostname that needs to be translated</li>
<li>On many UNIX-based machines, <code>gethostbyname()</code> is the
function call that an application calls in order to perform the
translation.</li>
<li>DNS in the user’s host then takes over, sending a query message into
the network.</li>
<li>All DNS query and reply messages are sent within UDP datagrams to
port 53.</li>
<li>After a delay, ranging from milliseconds to seconds, DNS in the
user’s host receives a DNS reply message that provides the desired
mapping</li>
<li>This mapping is then passed to the invoking application</li>
<li>A simple design for DNS would have one DNS server that contains all
the mappings. In this centralized design, clients simply direct all
queries to the single DNS server, and the DNS server responds directly
to the querying clients</li>
<li>However, while this idea is simple, by today’s standards, having
only one DNS server to store all the mappings is a terrible idea.</li>
<li>The problems with a centralized design are:
<ul>
<li>A <strong>single point of failure</strong>. If the DNS server
crashes, so does the entire Internet!</li>
<li><strong>Traffic volume</strong>. A single DNS server would have to
handle all DNS queries (for all the HTTP requests and e-mail messages
generated from hundreds of millions of hosts).</li>
<li><strong>Distant centralized database</strong>. A single DNS server
cannot be â€œclose to” all the querying clients. If we put the single
DNS server in New York City, then all que- ries from Australia must
travel to the other side of the globe, perhaps over slow and congested
links. This can lead to significant delays.</li>
<li><strong>Maintenance</strong>. The single DNS server would have to
keep records for all Internet hosts. Not only would this centralized
database be huge, but it would have to be updated frequently to account
for every new host.</li>
</ul></li>
<li>In summary, a centralized database in a single DNS server simply
doesn’t scale.</li>
<li>Consequently, the DNS is distributed by design.</li>
<li>In fact, the DNS is a great example of how a distributed database
can be implemented in the Internet.</li>
</ul>
<h4 id="a-distributed-hierarchical-database">A Distributed, Hierarchical
Database</h4>
<ul>
<li><p>In order to deal with the issue of scale, the DNS uses a large
number of servers, organized in a hierarchical fashion and distributed
around the world</p></li>
<li><p>No single DNS server has all of the mappings for all of the hosts
in the Internet, the mappings are distributed across the DNS
servers.</p></li>
<li><p>There are three classes of DNS servers:</p>
<ul>
<li>root DNS servers</li>
<li>top-level domain (TLD) DNS servers</li>
<li>authoritative DNS servers</li>
</ul></li>
<li><p><strong>Root DNS servers</strong>. There are more than 1000 root
servers instances scattered all over the world. These root servers are
copies of 13 different root servers, managed by 12 different
organizations, and coordinated through the Internet Assigned Numbers
Authority [IANA 2020]. Root name servers provide the IP addresses of the
TLD servers.</p></li>
<li><p><strong>Top-level domain (TLD) servers</strong>. For each of the
top-level domains–top-level domains such as com, org, net, edu, and gov,
and all of the country top-level domains such as uk, fr, ca, and jp,
there is TLD server (or server cluster).</p></li>
<li><p><strong>Authoritative DNS servers</strong>. Every organization
with publicly accessible hosts (such as Web servers and mail servers) on
the Internet must provide publicly accessible DNS records that map the
names of those hosts to IP addresses</p></li>
<li><p>An organization’s authoritative DNS server houses these DNS
records.</p></li>
<li><p>An organization can choose to implement its own authoritative DNS
server to hold these records; alternatively, the organization can pay to
have these records stored in an authoritative DNS server of some service
provider.</p></li>
<li><p>Most universities and large companies implement and maintain
their own primary and secondary (backup) authoritative DNS
server.</p></li>
<li><p>The root, TLD, and authoritative DNS servers all belong to the
hierarchy of DNS servers.</p></li>
<li><p>There is another important type of DNS server called the
<strong>local DNS server</strong></p></li>
<li><p>A local DNS server does not strictly belong to the hierarchy of
servers but is nevertheless central to the DNS architecture</p></li>
<li><p>Each ISP–such as a residential ISP or an institutional ISP–has a
local DNS server (also called a default name server)</p></li>
<li><p>When a host connects to an ISP, the ISP provides the host with
the IP addresses of one or more of its local DNS servers (typically
through DHCP)</p></li>
</ul>
<h4 id="dns-caching">DNS Caching</h4>
<ul>
<li><strong>DNS caching</strong> is a critically important feature of
the DNS system</li>
<li><strong>DNS caching</strong> is done in order to improve the delay
performance and to reduce the number of DNS messages ricocheting around
the Internet</li>
<li>In a query chain, when a DNS server receives a DNS reply
(containing, for example, a mapping from a hostname to an IP address),
it can cache the mapping in its local memory.</li>
<li>If you think about hash maps/Python dictionaries, that is what you
would use to cache a DNS (it is far more efficient than a silly
iterative approach)</li>
</ul>
<h3 id="dns-records-and-messages">2.4.3 DNS Records and Messages</h3>
<ul>
<li><p>The DNS servers that together implement the DNS distributed
database store <strong>resource records (RRs)</strong></p></li>
<li><p>Each DNS reply message carries one or more resource
records</p></li>
<li><p>A resource record is a four-tuple that contains the following
fields:</p>
<ul>
<li><code>(Name, Value, Type, TTL)</code></li>
</ul></li>
<li><p>TTL is the time to live of the resource record; it determines
when a resource should be removed from a cache.</p></li>
<li><p>The meaning of Name and Value depend on Type:</p>
<ul>
<li>If <code>Type=A</code>, then Name is a hostname and Value is the IP
address for the host- name. Thus, a Type A record provides the standard
hostname-to-IP address mapping. As an example,
(<code>relay1.bar.foo.com</code>, <code>145.37.93.126</code>,
<code>A</code>) is a Type A record.</li>
<li>If <code>Type=NS</code>, then Name is a domain (such as
<code>foo.com</code>) and Value is the host- name of an authoritative
DNS server that knows how to obtain the IP addresses for hosts in the
domain. This record is used to route DNS queries further along in the
query chain. As an example, (<code>foo.com</code>,
<code>dns.foo.com</code>, <code>NS</code>) is a Type NS record.</li>
<li>If <code>Type=CNAME</code>, then Value is a canonical hostname for
the alias hostname <code>Name</code>. This record can provide querying
hosts the canonical name for a hostname. As an example,
(<code>foo.com</code>, <code>relay1.bar.foo.com</code>,
<code>CNAME</code>) is a CNAME record</li>
<li>If <code>Type=MX</code>, then Value is the canonical name of a mail
server that has an alias hostname Name. As an example,
(<code>foo.com</code>, <code>mail.bar.foo.com</code>, <code>MX</code>)
is an MX record. MX records allow the hostnames of mail servers to have
simple aliases. Note that by using the MX record, a company can have the
same aliased name for its mail server and for one of its other servers
(such as its Web server). To obtain the canonical name for the mail
server, a DNS client would query for an MX record; to obtain the
canonical name for the other server, the DNS client would query for the
CNAME record.</li>
</ul></li>
<li><p>If a DNS server is authoritative for a particular hostname, then
the DNS server will contain a Type A record for the hostname.</p></li>
<li><p>If a server is not authoritative for a hostname, then the server
will contain a Type NS record for the domain that includes the hostname;
it will also contain a Type A record that provides the IP address of the
DNS server in the <code>Value</code> field of the NS record</p></li>
<li><p>Suppose an edu TLD server is not authoritative for the host
<code>gaia.cs.umass.edu</code></p></li>
<li><p>Then this server will contain a record for a domain that includes
the host <code>gaia.cs.umass.edu</code>, for example,
(<code>umass.edu</code>, <code>dns.umass.edu</code>,
<code>NS</code>)</p></li>
<li><p>The edu TLD server would also contain a Type A record, which maps
the DNS server <code>dns.umass.edu</code> to an IP address, for example,
(<code>dns.umass.edu</code>, <code>128.119.40.111</code>,
<code>A</code>)</p></li>
</ul>
<h4 id="dns-messages">DNS Messages</h4>
<ul>
<li>There are 2 different kinds of DNS messages.
<ol type="1">
<li>Queries</li>
<li>Replies</li>
</ol></li>
<li>Semantics of a DNS message:
<ul>
<li>The first 12 bytes is the <code>header section</code>, which has a
number of fields.</li>
<li>The first field is a 16-bit number that identifies the query</li>
<li>There are a number of flags in the flag field. A 1-bit query/reply
flag indicates whether the message is a query (0) or a reply (1)</li>
<li>A 1-bit authoritative flag is set in a reply message when a DNS
server is an authoritative server for a queried name</li>
<li>A 1-bit recursion-desired flag is set when a client (host or DNS
server) desires that the DNS server perform recursion when it doesn’t
have the record</li>
<li>A 1-bit recursion-available field is set in a reply if the DNS
server supports recursion</li>
<li>The <code>question section</code> contains information about the
query that is being made.</li>
<li>This section includes (1) a name field that contains the name that
is being queried, and (2) a type field that indicates the type of
question being asked about the name</li>
<li>A reply can return multiple <strong>RRs</strong> in the answer,
since a hostname can have multiple IP addresses</li>
<li>The <code>authority section</code> contains records of other
authoritative servers.</li>
<li>The additional section contains other helpful records.</li>
<li>For example, the answer field in a reply to an MX query contains a
resource record providing the canonical hostname of a mail server</li>
</ul></li>
</ul>
<p><strong>Q:</strong> How would you like to send a DNS query message
directly from the host you’re working on to some DNS server?</p>
<p><strong>A:</strong> This can easily be done with the <strong>nslookup
program</strong>, which can be found on most Windows and UNIX
platforms.</p>
<h4 id="inserting-records-into-the-dns-database">Inserting Records into
the DNS Database</h4>
<ul>
<li>Suppose you have just created an exciting new startup company called
Network Utopia.</li>
<li>The first thing you’ll surely want to do is register the domain name
<code>networkutopia.com</code> at a registrar</li>
<li>A <strong>registrar</strong> is a commercial entity that verifies
the uniqueness of the domain name, entersthe domain name into the DNS
database (as discussed below), and collects a small fee from you for its
services</li>
<li>Prior to 1999, a single registrar, Network Solutions, had a monopoly
on domain name registration for <code>com</code>, <code>net</code>, and
<code>org</code> domains</li>
<li>Now there are many registrars competing for customers, and the
Internet Corporation for Assigned Names and Numbers (ICANN) accredits
the various registrars</li>
<li>When you register the domain name <code>networkutopia.com</code>
with some registrar, you also need to provide the registrar with the
names and IP addresses of your primary and secondary authoritative DNS
servers</li>
<li>Suppose the names and IP addresses are
<code>dns1.networkutopia.com</code>,
<code>dns2.networkutopia.com</code>,<code>212.2.212.1</code>, and
<code>212.212.212.2</code></li>
<li>For each of these two authoritative DNS servers, the registrar would
then make sure that a Type NS and a Type A record are entered into the
TLD com servers.</li>
<li>Specifically, for the primary authoritative server for
<code>networkutopia.com</code>, the registrar would insert the following
two resource records into the DNS system</li>
</ul>
<pre><code>(networkutopia.com, dns1.networkutopia.com, NS)
(dns1.networkutopia.com, 212.212.212.1, A)</code></pre>
<h2 id="peer-to-peer-file-distribution">2.5 Peer-to-Peer File
Distribution</h2>
<ul>
<li>with a P2P architecture, there is minimal (or no) reliance on
always-on infrastructure servers. You rely on the peers that are
seeding.</li>
<li>The peers are not owned by a service provider, but are instead PCs,
laptops, and smartpones controlled by users.</li>
<li>In P2P file distribution, each peer can redistribute any portion of
the file it has received to any other peers, thereby assisting the
server in the distribution process</li>
</ul>
<h4 id="scalability-of-p2p-architectures">Scalability of P2P
Architectures</h4>
<ul>
<li><p>Let the upload rate of the server’s access link =
<code>Us</code></p></li>
<li><p>Let the upload rate of the ith peer’s access link =
<code>Ui</code></p></li>
<li><p>Let the download rate of the ith peer’s access link =
<code>di</code></p></li>
<li><p>Let the size of the file to be distributed (in bits) =
<code>F</code></p></li>
<li><p>Let and the number of peers that want to obtain a copy of the
file = <code>N</code></p></li>
<li><p>First, determine the distribution time for the client-server
architecture, which we will denoted with <code>Dcs</code></p>
<ul>
<li>The server must transmit one copy of the file to each of the
<code>N</code> peers. Thus, the server must transmit <code>NF</code>
bits. Since the server’s upload rate is <code>Us</code> , the time to
distribute the file must be at least <code>NF/Us</code></li>
<li>Let d min denote the download rate of the peer with the lowest
download rate, that is, <code>d min = min{ d1, dp, ... , dN }</code>.
The peer with the lowest download rate cannot obtain all <code>F</code>
bits of the file in less than <code>F/dmin</code> seconds. Thus, the
minimum distribution time is at least <code>F/dmin</code></li>
</ul></li>
<li><p>Combining these two observations together, we get:</p>
<ul>
<li><code>Dcs &gt;= max { (NF)/Us , F/dmin }</code></li>
</ul></li>
</ul>
<p>Now, let’s analyze the P2P architecture, where each peer can assist
the server in distributing the file. * At the beginning of the
distribution, only the server has the file. To get this file into the
community of peers, the server must send each bit of the file at least
once into its access link * Thus, the minimum distribution time is at
least <code>F/Us</code>. * As with the client-server architecture, the
peer with the lowest download rate cannot obtain all <code>F</code> bits
of the file in less than <code>F/dmin</code> seconds. Thus, the minimum
distribution time is at least <code>F/dmin</code> * Finally, observe
that the total upload capacity of the system as a whole is equal to the
upload rate of the server plus the upload rates of each of the
individual peers, that is, <code>Utotal = Us + U1 + ... + uN</code> .
The system must deliver (upload) <code>F</code> bits to each of the
<code>N</code> peers, thus delivering a total of <code>NF</code> bits.
This cannot be done at a rate faster than <code>Utotal</code> . Thus,
the minimum distribution time is also at least
<code>NF/(u s + u 1 + g + u N )</code>. - Combining these two
observations together, we get: *
<code>Dp2p &gt;= max { F/Us , F/dmin, (NF)/(Us + sum(1, N, Ui))</code></p>
<h4 id="bittorrent">BitTorrent</h4>
<ul>
<li>BitTorrent is a popular P2P protocol for file distribution</li>
<li>The collection of all peers participating in the distribution of a
particular file is called a torrent</li>
<li>Peers in a torrent download equal-size chunks of the file from one
another, with a typical chunk size of 256 KBytes</li>
<li>When a peer first joins a torrent, it has no chunks.</li>
<li>Over time it accumulates more and more chunks. While it downloads
chunks it also uploads chunks to other peers.</li>
<li>Once a peer has acquired the entire file, it may (selfishly) leave
the torrent, or (altruistically) remain in the torrent and continue to
upload chunks to other peers</li>
<li>Also, any peer may leave the torrent at any time with only a subset
of chunks, and later rejoin the torrent.</li>
<li>Alice uses a technique called <strong>rarest first</strong>. The
idea is to determine, from among the chunks she does not have, the
chunks that are the rarest among her neighbors (that is, the chunks that
have the fewest repeated copies among her neighbors) and then request
those rarest chunks first.</li>
<li>Seeders that supply high upload rates to leechers are said to be
<strong>unchoked</strong>.</li>
<li>A distributed hash table (DHT) is a simple database, with the
database records being distributed over the peers in a P2P system</li>
</ul>
<h2 id="video-streaming-and-content-distribution-networks">2.6 Video
Streaming and Content Distribution Networks</h2>
<ul>
<li>By many estimates, streaming video–including Netflix, YouTube and
Amazon Prime–account for about 80% of Internet traffic in 2020.</li>
</ul>
<h3 id="internet-video">2.6.1 Internet Video</h3>
<ul>
<li>From a networking perspective, perhaps the most salient
characteristic of video is its high bit rate.</li>
<li>Compressed Internet video typically ranges from 100 kbps for
low-quality video to over 4 Mbps for streaming high-definition
movies</li>
<li>4K streaming envisions a bitrate of more than 10 Mbp</li>
<li>We can also use compression to create multiple versions of the same
video, each at a different quality level. This is what YouTube does (and
pretty much all other streaming services)</li>
</ul>
<h3 id="http-streaming-and-dash">2.6.2 HTTP Streaming and DASH</h3>
<ul>
<li>In HTTP streaming, the video is simply stored at an HTTP server as
an ordinary file with a specific URL</li>
<li>When a user wants to see the video, the client establishes a TCP
connection with the server and issues an HTTP GET request for that
URL</li>
<li>The server then sends the video file, within an HTTP response
message, as quickly as the underlying network protocols and traffic
conditions will allow</li>
<li>On the client side, the bytes are collected in a client application
buffer</li>
<li><strong>Dynamic Adaptive Streaming over HTTP (DASH)</strong> is a
HTTP-based streaming protocol.</li>
<li>In DASH, the video is encoded into several different versions, with
each version having a different bit rate and, correspondingly, a
different quality level</li>
<li>The HTTP server also has a <strong>manifest file</strong>, which
provides a URL for each version along with its bit rate</li>
</ul>
<h3 id="content-distribution-networks">2.6.3 Content Distribution
Networks</h3>
<ul>
<li><p>In order to meet the challenge of distributing massive amounts of
video data to users distributed around the world, almost all major
video-streaming companies make use of Content Distribution Networks
(CDNs)</p></li>
<li><p>A CDN manages servers in multiple geographically distributed
locations, stores copies of the videos (and other types of Web content,
including documents, images, and audio) in its servers, and attempts to
direct each user request to a CDN location that will provide the best
user experience</p></li>
<li><p>The CDN may be a <strong>private CDN</strong>, a.k.a, owned by
the content provider itself</p></li>
<li><p>The CDN may alternatively be a <strong>third-party</strong> CDN
that distributes content on behalf of multiple content
providers</p></li>
<li><p>CDNs typically adopt one of two different server placement
philosophies:</p>
<ol type="1">
<li><strong>Enter Deep</strong>. One philosophy, pioneered by Akamai, is
to enter deep into the access networks of Internet Service Providers, by
deploying server clusters in access ISPs all over the world. Akamai
takes this approach with clusters in thousands of locations. The goal is
to get close to end users, thereby improving user-perceived delay and
throughput by decreasing the number of links and routers between the end
user and the CDN server from which it receives content</li>
<li><strong>Bring Home</strong>. A second design philosophy, taken by
Limelight and many other CDN companies, is to bring the ISPs home by
building large clusters at a smaller number (for example, tens) of
sites. Instead of getting inside the access ISPs, these CDNs typically
place their clusters in Internet Exchange Points (IXPs). Compared with
the enter-deep design philosophy, the bring-home design typically
results in lower maintenance and management overhead, possibly at the
expense of higher delay and lower throughput to end users</li>
</ol></li>
<li><p>Once its clusters are in place, the CDN replicates content across
its clusters</p></li>
</ul>
<h4 id="cdn-operation">CDN Operation</h4>
<ul>
<li>When a browser in a user’s host is instructed to retrieve a specific
video (identified by a URL), the CDN must intercept the request so that
it can:
<ol type="1">
<li>determine a suitable CDN server cluster for that client at that
time</li>
<li>redirect the client’s request to a server in that cluster</li>
</ol></li>
<li>Example:
<ol type="1">
<li>The user visits the Web page at NetCinema.</li>
<li>When the user clicks on the link
<code>http://video.netcinema.com/6Y7B23V</code>, the user’s host sends a
DNS query for <code>video.netcinema.com</code>.</li>
<li>The user’s Local DNS Server (LDNS) relays the DNS query to an
authoritative DNS server for NetCinema, which observes the string
“video” in the host- name video.netcinema.com. To â€œhand over” the DNS
query to KingCDN, instead of returning an IP address, the NetCinema
authoritative DNS server returns to the LDNS a hostname in the KingCDN’s
domain, for example, <code>a1105.kingcdn.com</code>.</li>
<li>From this point on, the DNS query enters into KingCDN’s private DNS
infrastructure. The user’s LDNS then sends a second query, now for
<code>a1105.kingcdn.com</code>, and KingCDN’s DNS system eventually
returns the IP addresses of a KingCDN content server to the LDNS. It is
thus here, within the KingCDN’s DNS system, that the CDN server from
which the client will receive its content is specified.</li>
<li>The LDNS forwards the IP address of the content-serving CDN node to
the user’s host.</li>
<li>Once the client receives the IP address for a KingCDN content
server, it establishes a direct TCP connection with the server at that
IP address and issues an HTTP GET request for the video. If DASH is
used, the server will first send to the client a manifest file with a
list of URLs, one for each version of the video, and the client will
dynamically select chunks from the different versions.</li>
</ol></li>
<li>At the core of any CDN deployment is a <strong>cluster selection
strategy</strong>, that is, a mechanism for dynamically directing
clients to a server cluster or a data center within the CDN</li>
<li>The CDN learns the IP address of the client’s LDNS server via the
client’s DNS lookup. After learning this IP address, the CDN needs to
select an appropriate cluster based on this IP address.</li>
<li>CDNs generally employ proprietary cluster selection strategies.</li>
<li>One simple strategy is to assign the client to the cluster that is
<strong>geographically closest</strong>.</li>
<li>In order to determine the best cluster for a client based on the
current traffic conditions, CDNs can instead perform periodic
<strong>real-time measurements</strong> of delay and loss performance
between their clusters and clients</li>
</ul>
<h3 id="case-studies-netflix-and-youtube">2.6.4 Case Studies: Netflix
and YouTube</h3>
<h4 id="netflix">Netflix</h4>
<ul>
<li>As of 2020, Netflix is the leading service provider for online
movies and TV series in North America.</li>
<li>As we discuss below, Netflix video distribution has two major
components:
<ul>
<li>The Amazon cloud</li>
<li>Its own private CDN infrastructure.</li>
</ul></li>
<li>Additionally, the Amazon cloud handles the following critical
functions:
<ul>
<li><strong>Content ingestion</strong>. Before Netflix can distribute a
movie to its customers, it mustfirst ingest and process the movie.
Netflix receives studio master versions of movies and uploads them to
hosts in the Amazon cloud.</li>
<li><strong>Content processing</strong>. The machines in the Amazon
cloud create many different formats for each movie, suitable for a
diverse array of client video players running on desktop computers,
smartphones, and game consoles connected to televisions. A different
version is created for each of these formats and at multiple bit rates,
allowing for adaptive streaming over HTTP using DASH.</li>
<li><strong>Uploading versions to its CDN</strong>. Once all of the
versions of a movie have been created, the hosts in the Amazon cloud
upload the versions to its CDN.</li>
<li>Once Netflix determines the CDN server that is to deliver the
content, it sends the client the IP address of the specific server as
well as a manifest file, which has the URLs for the different versions
of the requested movie</li>
<li>The client and that CDN server then directly interact using a
proprietary version of DASH</li>
</ul></li>
</ul>
<h4 id="youtube">YouTube</h4>
<ul>
<li>Similar to Netflix, Google uses its own private CDN to distribute
YouTube videos, and has installed server clusters in many hundreds of
different IXP and ISP locations</li>
<li>From these locations and directly from its huge data centers, Google
distributes YouTube videos</li>
<li>Unlike Netflix, however, Google uses pull caching, as described, and
DNS redirect.</li>
</ul>
<h2 id="socket-programming-creating-network-applications">2.7 Socket
Programming: Creating Network Applications</h2>
<ul>
<li>There are two types of network applications:
<ol type="1">
<li>One type is an implementation whose operation is specified in a
protocol standard, such as an RFC or some other standards document; such
an application is sometimes referred to as â€œopen,” since the rules
specifying its operation are known to all. For such an implementation,
the client and server programs must conform to the rules dictated by the
RFC.</li>
<li>The other type of network application is a proprietary network
application. In this case, the client and server programs employ an
application-layer protocol that has not been openly published in an RFC
or elsewhere. A single developer (or development team) creates both the
client and server programs, and the developer has complete control over
what goes in the code. But because the code does not implement an open
protocol, other independent developers will not be able to develop code
that interoperates with the application.</li>
</ol></li>
<li>Recall from the previous chapters that:
<ul>
<li>TCP is connection oriented and provides a reliable byte-stream
channel through which data flows between two end systems</li>
<li>UDP is connectionless and sends independent packets of data from one
end system to the other, without any guarantees about delivery</li>
<li>Recall also that when a client or server program implements a
protocol defined by an RFC, it should use the well-known port number
associated with the protocol; conversely, when developing a proprietary
application, the developer must be careful to avoid using such
well-known port numbers</li>
</ul></li>
</ul>
<h3 id="socket-programming-with-udp">2.7.1 Socket Programming with
UDP</h3>
<p><strong>Q:</strong> What goes into the destination address that is
attached to the packet?</p>
<p><strong>A:</strong> The destination host’s IP address is part of the
destination address. By including the destination IP address in the
packet, the routers in the Internet will be able to route the packet
through the Internet to the destination host. But because a host may be
running many network application processes, each with one or more
sockets, it is also necessary to identify the particular socket in the
destination host, i.e., the <strong>port number</strong> is assigned to
it. The packet’s destination address also includes the socket’s port
number.</p>
<ul>
<li>In summary, the sending process attaches to the packet a destination
address, which consists of the destination host’s IP address and the
destination socket’s port number.</li>
</ul>
<p><strong>Below is the TCP/UDP sending/receiving messages lab that we
did in Python.</strong></p>
<pre><code>1. The client reads a line of characters (data) from its keyboard and sends the data to the server.
2. The server receives the data and converts the characters to uppercase.
3. The server sends the modified data to the client.
4. The client receives the modified data and displays the line on its screen.</code></pre>
<h3 id="socket-programming-with-tcp">2.7.2 Socket Programming with
TCP</h3>
<ul>
<li><p>Unlike UDP, TCP is a connection-oriented protocol.</p></li>
<li><p>This means that before the client and server can start to send
data to each other, they first need to handshake and establish a TCP
connection</p></li>
<li><p>One end of the TCP connection is attached to the client socket
and the other end is attached to a server socket</p></li>
<li><p>When creating the TCP connection, we associate it with the client
socket address (IP address and port number) and the server socket
address (IP address and port number)</p></li>
<li><p>With the TCP connection established, when one side wants to send
data to the other side, it just drops the data into the TCP connection
via its socket.</p></li>
<li><p>This is different from UDP, for which the server must attach a
destination address to the packet before dropping it into the
socket.</p></li>
<li><p>In TCP, the client has the job of initiating contact with the
server. In order for the server to be able to react to the client’s
initial contact, the server has to be ready</p></li>
<li><p>This implies two things:</p>
<ol type="1">
<li>First, as in the case of UDP, the TCP server must be running as a
process before the client attempts to initiate contact.</li>
<li>Second, the server program must have a special door–more precisely,
a special socket–that welcomes some initial contact from a client
process running on an arbitrary host.</li>
</ol></li>
<li><p>With the server process running, the client process can initiate
a TCP connection to the server. This is done in the client program by
creating a TCP socket.</p></li>
<li><p>When the client creates its TCP socket, it specifies the address
of the welcoming socket in the server, namely, the IP address of the
server host and the port number of the socket.</p></li>
<li><p>After creating its socket, the client initiates a three-way
handshake and establishes a TCP connection with the server.</p></li>
<li><p>The three-way handshake, which takes place within the transport
layer, is completely invisible to the client and server
programs</p></li>
<li><p>During the three-way handshake, the client process knocks on the
welcoming door of the server process.</p></li>
<li><p>When the server “hears” the knocking, it creates a new
door/socket dedicated to that client.</p></li>
</ul>
</body>
</html>
